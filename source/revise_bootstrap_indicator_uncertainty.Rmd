---
title: "Calculate biodiversity indicator uncertainty via bootstrapping on the complete cube"
author: "Ward Langeraert"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    toc: true
    toc_float: true
    toc_collapsed: true
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../output/reports") })
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE, message=FALSE}
# Load packages
library(b3gbi)       # Biodiversity indicators for data cubes
library(tidyverse)   # Data wrangling and visualisation
library(here)        # Relative paths
library(effectclass) # Classification and visualisation of effects
library(knitr)       # Nice tables

# Source functions
source(here("source", "R", "bootstrap_cube.R"))
source(here("source", "R", "get_bootstrap_ci.R"))
source(here("source", "R", "cross_validate_species.R"))
source(here("source", "R", "add_classification_as_factor.R"))
source(here("source", "R", "utils.R"))

# Cache folder
cache_path <- here("data", "cache")
dir.create(cache_path, showWarnings = FALSE, recursive = TRUE)
out_path <- here("output", "figures",
                 "revise_bootstrap_indicator_uncertainty")
dir.create(out_path, showWarnings = FALSE, recursive = TRUE)
```

# Goal

We developed functions for bootstrapping in `bootstrap_indicator_uncertainty_old.Rmd`.
However, these were not correctly implemented and not scalable for all indicator functions.
In this document, we revise the bootstrapping functions and require input as a `"processed_cube"` object as created by `b3gbi::process_cube()` and functions should be able to process these objects.

# Exploration of the b3gbi package

We install b3gbi package version 0.2.2.
We load a dataset from the package.
How does the cube look like?

```{r}
# Load GBIF data cube
cube_name <- system.file("extdata", "europe_insect_cube.csv", package = "b3gbi")

# Load taxonomic info for cube
tax_info <- system.file("extdata", "europe_insect_info.csv", package = "b3gbi")

insect_data_df <- read.csv(cube_name)
head(insect_data_df)
```

We process the cube.

```{r}
# Prepare cube
insect_data <- process_cube_old(cube_name, tax_info)

insect_data
```

```{r}
# Calculate diversity metric
map_obs_rich_insects <- obs_richness_map(insect_data)

print(map_obs_rich_insects)
```

```{r}
# Plot diversity metric
plot(map_obs_rich_insects,
     title = "Observed Species Richness: Insects in Europe")
```

## Calculate an index over time

Let's calculate Pielou's evenness over time using b3gbi.

```{r}
eveness_insect_data <- pielou_evenness_ts(insect_data)
tail(eveness_insect_data$data)
```

```{r}
plot(eveness_insect_data)
```

## Conclusion

The visualisation of uncertainty in trends is not correct because of two factors:

1. Uncertainty is based on evenness values per year and is not based on the data itself
2. The predicted evenness becomes negative although evenness is a value between 0 and 1

Let's calculate this metric from scratch in the next section.
We select the data after 2010 to ensure calculations with enough data.

```{r}
insect_data_new <- process_cube_old(cube_name, tax_info, first_year = 2011)

insect_data_new$data %>%
  group_by(year) %>%
  summarise(n_obs = sum(obs)) %>%
  ggplot() +
    geom_bar(aes(x = as.factor(year), y = n_obs), stat = "identity") +
    labs(x = "year", y = "number of observations")
```

# Bootstrapping
## Bootstrap statistics and intervals

We perform bootstrapping for evenness.
Bootstrapping is a statistical technique used to estimate the distribution of a statistic by resampling with replacement from the original data.
Below are the common notations used in bootstrapping:

1. **Original Sample Data**: $\mathbf{X} = \{X_1, X_2, \ldots, X_n\}$
    - The initial set of observed data points. Here, $n$ is the sample size.
    
2. **Statistic of Interest**: $\theta$
    - The parameter or statistic being estimated, such as the mean $\bar{X}$, variance $\sigma^2$, or median.  Let $\hat{\theta}$ denote the estimated value of $\theta$ calculated from the complete dataset $\mathbf{X}$.

3. **Bootstrap Sample**: $\mathbf{X}^* = \{X_1^*, X_2^*, \ldots, X_n^*\}$
    - A sample of size $n$ drawn with replacement from the original sample $\mathbf{X}$. Each $X_i^*$ is drawn independently from $\mathbf{X}$.

4. **Bootstrap Replication**: $\hat{\theta}^*_b$
    - The value of the statistic of interest calculated from the $b$-th bootstrap sample $\mathbf{X}^*_b$. For example, if $\theta$ is the sample mean, $\hat{\theta}^*_b = \bar{X}^*_b$.

5. **Number of Bootstrap Samples**: $B$
    - The number of bootstrap samples drawn from the original data. Common choices for $B$ are 1000 or 10,000 to ensure a good approximation of the distribution.

6. **Bootstrap Estimate of the Statistic**: $\hat{\theta}_{\text{boot}}$
    - The average of the bootstrap replications:

$$
\hat{\theta}_{\text{boot}} = \frac{1}{B} \sum_{b=1}^B \hat{\theta}^*_b
$$

7. **Bootstrap Standard Error**: $\text{SE}_{\text{boot}}$
    - The standard deviation of the bootstrap replications, which estimates the variability of the statistic.

8. **Bootstrap Bias**: $\text{Bias}_{\text{boot}}$
    - This bias indicates how much the bootstrap estimate deviates from the original sample estimate. It is calculated as the difference between the average bootstrap estimate and the original estimate:

$$
\text{Bias}_{\text{boot}} = \frac{1}{B} \sum_{b=1}^B (\hat{\theta}^*_b - \hat{\theta}) = \hat{\theta}_{\text{boot}} - \hat{\theta}
$$

8. **Bootstrap Confidence Interval**
    - Confidence intervals for the statistic of interest can be constructed using the bootstrap distribution of $\hat{\theta}^*$. Several methods are explained below.

First we perform bootstrapping.
We calculate `b3gbi::pielou_evenness_ts` on the insect data from after 2010.

```{r, echo=FALSE, message=FALSE}
# Bootstrapping
bootstrap_insect_data_path <- file.path(cache_path, "bootstrap_insect_data.Rds")
if (file.exists(bootstrap_insect_data_path)) {
  bootstrap_insect_data <- readRDS(bootstrap_insect_data_path)
} else {
  bootstrap_insect_data <- bootstrap_cube(
    data_cube = insect_data_new,
    fun = b3gbi::pielou_evenness_ts,
    grouping_var = "year",
    samples = 1000,
    seed = 123,
    progress = TRUE)
  saveRDS(bootstrap_insect_data, bootstrap_insect_data_path)
}
```

```r
bootstrap_insect_data <- bootstrap_cube(
  data_cube = insect_data_new,
  fun = b3gbi::pielou_evenness_ts,
  grouping_var = "year",
  samples = 1000,
  seed = 123,
  progress = TRUE)
```

We visualise the distribution of the bootstrap replicates
The bootstrap bias is the difference between the estimate and the bootstrap estimate.

```{r, fig.width = 10, echo=FALSE, warning=FALSE}
bias_df <- bootstrap_insect_data %>%
  distinct(year, estimate = est_original, `bootstrap estimate` = est_boot)

estimate_df <- bias_df %>%
  pivot_longer(cols = c("estimate", "bootstrap estimate"),
               names_to = "Legend", values_to = "value") %>%
  mutate(Legend = factor(Legend, levels = c("estimate", "bootstrap estimate"),
                         ordered = TRUE))

bootstrap_insect_data %>%
  ggplot(aes(x = year)) +
    geom_violin(aes(y = rep_boot, group = year)) +
    geom_segment(data = bias_df,
                 aes(xend = year, y = estimate, yend = `bootstrap estimate`),
                 colour = "cornflowerblue", linewidth = 1) +
    geom_point(data = estimate_df, aes(y = value, shape = Legend),
               colour = "firebrick", size = 2) +
    labs(y = "evenness") +
    theme(legend.position = "bottom") +
    scale_y_continuous(limits = c(0, 1), breaks = seq(-10, 10, 0.25)) +
    scale_x_continuous(breaks = sort(unique(bootstrap_insect_data$year)))
```

There are multiple intervals that can be calculated, see `bootstrap_indicator_uncertainty_old.Rmd`.

```{r, echo=FALSE, message=FALSE}
# Bootstrapping
ci_insect_data_path <- file.path(cache_path, "ci_df.Rds")
if (file.exists(ci_insect_data_path)) {
  ci_df <- readRDS(ci_insect_data_path)
} else {
  # Calculate confidence intervals
  ci_df <- get_bootstrap_ci(
    bootstrap_samples_df = bootstrap_insect_data,
    grouping_var = "year",
    type = c("perc", "bca", "norm", "basic"),
    conf = 0.95,
    aggregate = TRUE,
    data_cube = insect_data_new,
    fun = b3gbi::pielou_evenness_ts,
    progress = TRUE)
  saveRDS(ci_df, ci_insect_data_path)
}
```

```r
ci_df <- get_bootstrap_ci(
  bootstrap_samples_df = bootstrap_insect_data,
  grouping_var = "year",
  type = c("perc", "bca", "norm", "basic"),
  conf = 0.95,
  aggregate = TRUE,
  data_cube = insect_data_new,
  fun = b3gbi::pielou_evenness_ts,
  progress = TRUE)
```

## Visualise confidence intervals

We visualise the distribution of the bootstrap replicates and the confidence intervals.

```{r, fig.width = 10, echo=FALSE, warning=FALSE}
p <- bootstrap_insect_data %>%
  ggplot(aes(x = year)) +
    geom_violin(aes(y = rep_boot, group = year),
                fill = alpha("cornflowerblue", 0.2)) +
    geom_point(data = estimate_df, aes(y = value, shape = Legend),
               colour = "firebrick", size = 2, alpha = 0.5) +
    geom_errorbar(data = ci_df, aes(ymin = ll, ymax = ul, colour = int_type),
                  position = position_dodge(0.8), linewidth = 1) +
    labs(y = "evenness", colour = "Interval type:", x = "",
         shape = "Legend:") +
    scale_y_continuous(limits = c(NA, 1), breaks = seq(-10, 10, 0.25)) +
    scale_x_continuous(breaks = sort(unique(bootstrap_insect_data$year))) +
    theme_minimal() +
    theme(legend.position = "bottom")
p
```

The interval width increases when the bootstrap standard error increases, as expected.

```{r, echo=FALSE}
ci_df %>%
  mutate(ci_width = ul - ll) %>%
  distinct(year, se_boot, int_type, ci_width) %>%
  ggplot(aes(x = se_boot, y = ci_width, colour = int_type)) +
    geom_point() +
    geom_smooth(method = "lm", formula = "y ~ x") +
    labs(x = "bootstrap standard error", y = "interval width",
         colour = "Confidence\ninterval")
```

```{r, echo=FALSE}
ci_df %>%
  mutate(ci_width = ul - ll) %>%
  distinct(year, se_boot, int_type, ci_width) %>%
  group_by(int_type) %>%
  group_modify(~ grouped_regression(df = ., formula = ci_width ~ se_boot)) %>%
  ungroup() %>%
  filter(param == "se_boot") %>%
  kable()
```

We see no clear relation to bias.

```{r, echo=FALSE}
ci_df %>%
  mutate(ci_width = ul - ll) %>%
  distinct(year, bias_boot, int_type, ci_width) %>%
  ggplot(aes(x = bias_boot, y = ci_width, colour = int_type)) +
    geom_point() +
    geom_smooth(method = "lm", formula = "y ~ x") +
    labs(x = "bootstrap bias", y = "interval width",
         colour = "Confidence\ninterval")
```

```{r, echo=FALSE}
ci_df %>%
  mutate(ci_width = ul - ll) %>%
  distinct(year, bias_boot, int_type, ci_width) %>%
  group_by(int_type) %>%
  group_modify(~ grouped_regression(df = ., formula = ci_width ~ bias_boot)) %>%
  ungroup() %>%
  filter(param == "bias_boot") %>%
  kable()
```

There is some discussion on the use of [the percentile interval](https://stats.stackexchange.com/questions/355781/is-it-true-that-the-percentile-bootstrap-should-never-be-used).
The BCa approach takes into account both bias and skewness and seems to be the best method for the complete range of estimates from all possible indicator functions.
However it takes some time to do the jackknife estimation.

# Influence of species on indicator value

In the previous section, we looked at the bootstrap sample distribution. For some years, the bootstrap distribution has very long tails.
This might be due to species having a much larger number of observations compared to others.
During the resampling process of bootstrapping, they might be included or not, which results in large variability in the indicator value.

```{r, echo=FALSE}
p_nobs <- insect_data_new$data %>%
  summarise(n = sum(obs), .by = c("year", "taxonKey")) %>%
  ggplot(aes(x = as.factor(year), y = n, colour = as.factor(taxonKey))) +
    geom_text(aes(label = as.factor(taxonKey))) +
    labs(x = "", y = "Number of Observations") +
    theme_minimal() +
    theme(
      axis.text = element_text(size = 12),
      axis.title = element_text(size = 15)
    ) +
    theme(legend.position = "")
p_nobs
```

```{r}
ggsave(
  filename = file.path(out_path, "number_of_obs.png"),
  plot = p_nobs,
  dpi = 300,
  width = 10,
  height = 6)
```

We can calculate a measure for each species of how much it influences the indicator.
Like leave-one-out cross-validation, but where we leave out one species each time.
Below are the notations used in leave-one-species-out cross-validation:

1. **Original Sample Data**: $\mathbf{X} = \{X_{11}, X_{12}, X_{13}, \ldots, X_{sn}\}$
    - The initial set of observed data points, where there are $s$ different species and $n$ total samples across all species.
    
2. **Statistic of Interest**: $\theta$
    - The parameter or statistic being estimated, such as the mean $\bar{X}$, variance $\sigma^2$, or median. Let $\hat{\theta}$ denote the estimated value of $\theta$ calculated from the complete dataset $\mathbf{X}$.

3. **Cross-Validation (CV) Sample**: $\mathbf{X}_{-s_j}$
    - The full dataset $\mathbf{X}$ excluding all samples belonging to species $j$. This subset is used for training the model when evaluating the performance for species $j$.

4. **CV Estimate for Species** $\mathbf{j}$: $\hat{\theta}_{-s_j}$
    - The value of the statistic of interest calculated from $\mathbf{X}_{-s_j}$, which excludes species $j$.
    
5. **Error Measures**: 
   - The **Error** is the difference between the statistic estimated without species $j$ ($\hat{\theta}_{-s_j}$) and the statistic calculated on the complete dataset ($\hat{\theta}$).

$$
\text{Error}_{s_j} = \hat{\theta}_{-s_j} - \hat{\theta}
$$

   - The **Relative Error** is the absolute error, normalised by the true estimate $\hat{\theta}$ and a small error term $\epsilon = 10^{-8}$ to avoid division by zero.

<!-- spell-check: ignore:start -->
$$
\text{Rel. Error}_{s_j} = \frac{| \hat{\theta}_{-s_j} - \hat{\theta}|}{\hat{\theta} +\epsilon}
$$
<!-- spell-check: ignore:end -->

6. **Summary Measures**:
   - The **Mean Relative Error (MRE)** is the average of the relative errors over all species:
<!-- spell-check: ignore:start -->
$$
\text{MRE} = \frac{1}{s} \sum_{j=1}^s \text{Rel. Error}_{s_j}
$$
<!-- spell-check: ignore:end -->
   - The **Mean Squared Error (MSE)** is the average of the squared errors:
$$
\text{MSE} = \frac{1}{s} \sum_{j=1}^s (\text{Error}_{s_j})^2
$$
   - The **Root Mean Squared Error (RMSE)** is the square root of the MSE:
$$
\text{RMSE} = \sqrt{\text{MSE}}
$$

```{r, echo=FALSE, message=FALSE}
# Bootstrapping
cv_results_loo_path <- file.path(
  cache_path, "cv_results_loo.Rds")
if (file.exists(cv_results_loo_path)) {
  cv_results_loo <- readRDS(cv_results_loo_path)
} else {
  cv_results_loo <- cross_validate_species(
    data_cube = insect_data_new,
    fun = b3gbi::pielou_evenness_ts,
    grouping_var = "year",
    crossv_method = "loo",
    progress = TRUE)
  saveRDS(cv_results_loo, cv_results_loo_path)
}
```

```r
cv_results_loo <- cross_validate_species(
  data_cube = insect_data_new,
  fun = b3gbi::pielou_evenness_ts,
  grouping_var = "year",
  crossv_method = "loo",
  progress = TRUE)
```

```{r, echo=FALSE}
original_ests <- cv_results_loo %>%
  distinct(year, est_original) %>%
  mutate(label = paste("hat(theta) ==", round(est_original, 3)))
p_loo_error <- ggplot(cv_results_loo, aes(x = as.factor(year))) +
  geom_hline(yintercept = 0, colour = "black", linetype = "dashed") +
  geom_text(aes(y = error, colour = as.factor(species_left_out),
                label = as.factor(species_left_out))) +
  geom_label(data = original_ests, aes(label = label), y = 0.9, parse = TRUE) +
  labs(x = "", y = "LOSO-CV Error") +
  scale_y_continuous(breaks = seq(-1, 1, 0.2), limits = c(-0.25, 0.9)) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 15)
  ) +
  theme(legend.position = "") +
  # Add arrows to indicate direction commonness in regions
  annotate("segment",
    x = length(unique(cv_results_loo$year)) + 0.4,
    y = -0.035,
    xend = length(unique(cv_results_loo$year)) + 0.4,
    yend = -0.2,
    arrow = arrow(type = "closed", length = unit(0.01, "npc")),
    colour = "black"
  ) +
  annotate("segment",
    x = length(unique(cv_results_loo$year)) + 0.4,
    y = 0.035,
    xend = length(unique(cv_results_loo$year)) + 0.4,
    yend = 0.2,
    arrow = arrow(type = "closed", length = unit(0.01, "npc")),
    colour = "black"
  ) +
  annotate("text",
    label = c("Decreases evenness"),
    x = length(unique(cv_results_loo$year)) + 0.5,
    y = -0.035,
    size = 3, hjust = "right", colour = "black", angle = 90
  ) +
  annotate("text",
    label = c("Increases evenness"),
    x = length(unique(cv_results_loo$year)) + 0.5,
    y = 0.035,
    size = 3, hjust = "left", colour = "black", angle = 90
  )
p_loo_error
```

```{r}
ggsave(
  filename = file.path(out_path, "eveness_loo_error.png"),
  plot = p_loo_error,
  dpi = 300,
  width = 10,
  height = 6)
```

We look at the relative error (RE).

```{r, fig.width = 10, echo=FALSE}
# Define custom break points
break_points <- c(
  10, seq(25, max(cv_results_loo$perc_diff, na.rm = TRUE) + 25, 25)
  )

# Apply custom breaks
cv_results_loo <- cv_results_loo %>%
  filter(perc_diff >= 10) %>%
  mutate(
    perc_diff_category = cut(
      perc_diff,
      breaks = break_points,
      right = TRUE,
      include.lowest = TRUE))

cv_results_loo %>%
  count(year, perc_diff_category, name = "n_species") %>%
  kable()
```

Do we get similar values for the summary statistics if we use k-fold cross-validation?

```{r, message=FALSE}
cv_results_kfold <- cross_validate_species(
  data_cube = insect_data_new,
  fun = b3gbi::pielou_evenness_ts,
  grouping_var = "year",
  crossv_method = "kfold",
  k = 10,
  progress = TRUE)
```

They are very different.

```{r, echo=FALSE}
mean_cv_stats_loo <- cv_results_loo %>%
  mutate(
    mean_abs_diff = mean(abs_diff),
    mean_perc_diff = mean(perc_diff),
    .by = year
  ) %>%
  distinct(year, mean_abs_diff, mean_perc_diff, mse, rmse) %>%
  mutate(crossv_method = "loo")

mean_cv_stats_kfold <- cv_results_kfold %>%
  mutate(
    mean_abs_diff = mean(abs_diff),
    mean_perc_diff = mean(perc_diff),
    .by = year
  ) %>%
  distinct(year, mean_abs_diff, mean_perc_diff, mse, rmse) %>%
  mutate(crossv_method = "kfold")

bind_rows(mean_cv_stats_loo, mean_cv_stats_kfold) %>%
  arrange(year) %>%
  kable()
```

# Interpretation and visualisation of uncertainty

Here we will follow the methods implemented by the [effectclass package](https://inbo.github.io/effectclass/).
It classifies effects by comparing a coverage interval with a reference, lower and upper threshold.
The benefits of this approach are twofold:

1. A visual tool that simplifies interpretation of results, even for people who are not familiar with the data and/or methods used
2. The use of arbitrary thresholds allows to make the distinction between 'no effect' (small interval covering reference) and 'uncertain effect' (large interval covering reference and one or both thresholds)

```{r, echo=FALSE}
ds <- data.frame(
  mean = c(0, 0.5, -0.5, 1, -1, 1.5, -1.5, 0.5, -0.5, 0),
  sd = c(1, 0.5, 0.5, 0.5, 0.5, 0.25, 0.25, 0.25, 0.25, 0.5)
)
ds$lcl <- qnorm(0.05, ds$mean, ds$sd)
ds$ucl <- qnorm(0.95, ds$mean, ds$sd)
ds$effect <- classification(ds$lcl, ds$ucl, 1)
ggplot(ds, aes(x = effect, y = mean, ymin = lcl, ymax = ucl, link_sd = sd)) +
  stat_effect(threshold = 1)
```

## Comparing with a constant

We select the summary statistics. We only focus on the percentile interval.

```{r}
summary_df <- ci_df %>%
  filter(int_type == "perc") %>%
  select(year, est_original, ll, ul, conf, int_type)
```

```{r, echo=FALSE}
summary_df %>%
  kable()
```

Let's say we want to test whether the evenness of insects differs from 0.5.
We use thresholds of 0.1 to distinguish between strong and moderate effects.

```{r}
# Add classification based on reference and thresholds
insect_eveness_effects <- add_classification_as_factor(
  df = summary_df,
  cl_columns = c("ll", "ul"),
  threshold = 0.1,
  reference = 0.5,
  coarse = TRUE)
```

```{r, echo=FALSE}
insect_eveness_effects %>%
  kable(digits = 3)
```

We can visualise this as such.
Coarse classification:

```{r}
insect_eveness_effects %>%
  ggplot(aes(x = year, y = est_original, ymin = ll, ymax = ul)) +
    stat_effect(reference = 0.5, threshold = c(0.4, 0.6), detailed = FALSE) +
    labs(y = "evenness") +
    scale_y_continuous(limits = c(0, 1), breaks = seq(-10, 10, 0.25)) +
    scale_x_continuous(breaks = sort(unique(insect_eveness_effects$year)))
```

We can create this figure ourselves:

```{r}
insect_eveness_effects %>%
  ggplot(aes(x = year)) +
    geom_hline(yintercept = 0.5, linetype = "longdash", colour = "black") +
    geom_hline(yintercept = c(0.4, 0.6), linetype = "dotdash") +
    geom_errorbar(aes(ymin = ll, ymax = ul, colour = effect_coarse),
                  linewidth = 1.5, show.legend = TRUE) +
    geom_point(aes(y = est_original), colour = "black", size = 3.5) +
    scale_colour_manual(values =  c("chartreuse3",
                                    "gold",
                                    "firebrick1",
                                    "skyblue"),
                        drop = FALSE) +
    labs(y = "evenness", colour = "Classification") +
    scale_y_continuous(limits = c(0, 1), breaks = seq(-10, 10, 0.25)) +
    scale_x_continuous(breaks = sort(unique(insect_eveness_effects$year))) +
    theme_minimal()
```

Fine classification:

```{r}
insect_eveness_effects %>%
  ggplot(aes(x = year, y = est_original, ymin = ll, ymax = ul)) +
  stat_effect(threshold = c(0.4, 0.6), reference = 0.5) +
  labs(y = "evenness") +
  scale_y_continuous(limits = c(0, 1), breaks = seq(-10, 10, 0.25)) +
  scale_x_continuous(breaks = sort(unique(insect_eveness_effects$year)))
```

```{r, fig.width = 10, echo=FALSE, warning=FALSE}
my_theme <- theme_minimal() +
    theme(
      axis.text = element_text(size = 12),
      axis.title = element_text(size = 15)
    ) +
    theme(
      legend.title = element_text(face = "bold", size = 12),
      legend.text = element_text(size = 12)
      )

p_effect_evenness <- insect_eveness_effects %>%
  ggplot(aes(x = year)) +
    geom_hline(yintercept = 0.5, linetype = "longdash", colour = "black") +
    geom_hline(yintercept = c(0.4, 0.6), linetype = "dotdash") +
    geom_errorbar(aes(ymin = ll, ymax = ul, colour = effect),
                  linewidth = 1.5, show.legend = TRUE) +
    geom_point(aes(y = est_original), colour = "black", size = 3.5) +
    scale_colour_manual(values =  c("darkgreen",
                                    "chartreuse3",
                                    "darkolivegreen1",
                                    "gold",
                                    "orange",
                                    "firebrick1",
                                    "darkred",
                                    "gray80",
                                    "gray30",
                                    "grey55"),
                        drop = FALSE) +
    labs(x = "", y = "Pielou's Evenness", colour = "Classification:") +
    scale_y_continuous(limits = c(0, 1), breaks = seq(-10, 10, 0.25)) +
    scale_x_continuous(breaks = sort(unique(insect_eveness_effects$year))) +
    my_theme
p_effect_evenness
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
ggsave(
  filename = file.path(out_path, "eveness_effect_constant.png"),
  plot = p_effect_evenness,
  dpi = 300,
  width = 10,
  height = 6)
```

## Comparing with a statistic

Often, we do not want to compare with an arbitrary value.
In case of time series, we often want to compare values of certain years with a reference year, e.g. the first year of the series.
For any two random variables:

<!-- spell-check: ignore:start -->
$$
\text{Var}(X - Y) = \text{Var}(X) + \text{Var}(Y) - 2\text{Cov}(X, Y)
$$
<!-- spell-check: ignore:end -->

However, in case of our bootstrapping examples, we cannot use the (co)variance directly to calculate most confidence intervals of the difference.
Therefore, we should also bootstrap over the difference such that we can calculate all intervals.
This can be done using the `ref_group` argument.

```{r, echo=FALSE, message=FALSE}
# Bootstrapping
bootstrap_insect_data_path2 <- file.path(
  cache_path, "bootstrap_insect_data_diff.Rds")
if (file.exists(bootstrap_insect_data_path2)) {
  bootstrap_insect_data_diff <- readRDS(bootstrap_insect_data_path2)
} else {
  bootstrap_insect_data_diff <- bootstrap_cube(
    data_cube = insect_data_new,
    fun = b3gbi::pielou_evenness_ts,
    grouping_var = "year",
    samples = 1000,
    ref_group = 2020,
    seed = 123,
    progress = TRUE)
  saveRDS(bootstrap_insect_data_diff, bootstrap_insect_data_path2)
}
```

```r
bootstrap_insect_data_diff <- bootstrap_cube(
  data_cube = insect_data_new,
  fun = b3gbi::pielou_evenness_ts,
  grouping_var = "year",
  samples = 1000,
  ref_group = 2020,
  seed = 123,
  progress = TRUE)
```

We calculate the percentile interval.

```{r}
# Calculate confidence intervals
ci_diff_df <- get_bootstrap_ci(
  bootstrap_samples_df = bootstrap_insect_data_diff,
  grouping_var = "year",
  type = "perc",
  conf = 0.95,
  aggregate = TRUE)
```

We visualise the intervals.

```{r, fig.width = 10, echo=FALSE, warning=FALSE}
estimate_diff_df <- bootstrap_insect_data_diff %>%
  distinct(year, estimate = est_original, `bootstrap estimate` = est_boot) %>%
  pivot_longer(cols = c("estimate", "bootstrap estimate"),
               names_to = "Legend", values_to = "value") %>%
  mutate(Legend = factor(Legend, levels = c("estimate", "bootstrap estimate"),
                         ordered = TRUE))

bootstrap_insect_data_diff %>%
  ggplot(aes(x = year)) +
    geom_violin(aes(y = rep_boot, group = year)) +
    geom_point(data = estimate_diff_df, aes(y = value, shape = Legend),
               colour = "firebrick", size = 3, alpha = 0.5) +
    geom_errorbar(data = ci_diff_df, aes(ymin = ll, ymax = ul),
                  linewidth = 1, width = 0.4, colour = "cornflowerblue") +
    labs(y = "evenness") +
    scale_y_continuous(limits = c(-1, 1), breaks = seq(-10, 10, 0.25)) +
    scale_x_continuous(breaks = sort(unique(bootstrap_insect_data_diff$year))) +
    theme_minimal() +
    theme(legend.position = "bottom")
```

We classify the effects as we did before.
This time our reference is 0 (no change with 2020) and we choose an arbitrary threshold of 0.2.

```{r}
# Select data for visualisation
summary_diff_df <- ci_diff_df %>%
  select(year, est_original, ll, ul, conf, int_type)

# Add classification based on reference and thresholds
insect_eveness_diff_effects <- add_classification_as_factor(
  df = summary_diff_df,
  cl_columns = c("ll", "ul"),
  threshold = 0.2,
  reference = 0,
  coarse = TRUE)
```

```{r, echo=FALSE}
insect_eveness_diff_effects %>%
  kable(digits = 3)
```

We visualise these effects.

```{r, fig.width = 10, echo=FALSE}
# Visualise
p_effect_evenness2 <- insect_eveness_diff_effects %>%
  ggplot(aes(x = year)) +
    geom_hline(yintercept = 0, linetype = "longdash", colour = "black") +
    geom_hline(yintercept = c(-0.2, 0.2), linetype = "dotdash") +
    geom_errorbar(aes(ymin = ll, ymax = ul, colour = effect),
                  linewidth = 1.5, show.legend = TRUE) +
    geom_point(aes(y = est_original), colour = "black", size = 3.5) +
    scale_colour_manual(values =  c("darkgreen",
                                    "chartreuse3",
                                    "darkolivegreen1",
                                    "gold",
                                    "orange",
                                    "firebrick1",
                                    "darkred",
                                    "gray80",
                                    "gray30",
                                    "grey55"),
                        drop = FALSE) +
    labs(x = "", y = "Difference in Pielou's Evenness\ncompared to 2020",
         colour = "Classification:") +
    scale_y_continuous(limits = c(-1, 1), breaks = seq(-10, 10, 0.25)) +
    scale_x_continuous(breaks = sort(unique(insect_eveness_effects$year))) +
    my_theme
p_effect_evenness2
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
ggsave(
  filename = file.path(out_path, "eveness_effect_ref.png"),
  plot = p_effect_evenness2,
  dpi = 300,
  width = 10,
  height = 6)
```

# Conclusion

Although these methods require additional testing, the first results show that bootstrapping can be used to correctly visualise and interpret trends from indicators based on biodiversity data cubes.

*What's next?*

- Test workflow on other datasets
- Test workflow on other indicators
- How long does bootstrapping take for big datasets?
- How long does cross-validation take for big datasets?
- Error handling
  - Bootstrapping and confidence interval calculations do not always work with few data
